#!/usr/bin/env python3
"""
ğŸ”§ Script de correction pour l'erreur d'import PriceScraperTFIDF
"""

import os
import sys
from pathlib import Path

def fix_price_scraper():
    """Corrige le module price_scraper pour exporter PriceScraperTFIDF"""
    
    price_scraper_path = Path("src/extractor/price_scraper.py")
    
    # Contenu corrigÃ© du price_scraper.py
    content = '''"""
ğŸ’° Price Scraper avec TF-IDF et sources multiples
"""

import pandas as pd
import time
import logging
import os
import sys
import re
import requests
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
logger = logging.getLogger(__name__)

# Import optionnel de Selenium
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    logger.warning("Selenium non disponible - scraping dÃ©sactivÃ©")

# Import optionnel de scikit-learn pour TF-IDF
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("scikit-learn non disponible - TF-IDF dÃ©sactivÃ©")

class GameTitleMatcher:
    """Matcher de titres de jeux utilisant TF-IDF"""
    
    def __init__(self, similarity_threshold: float = 0.6):
        self.similarity_threshold = similarity_threshold
        
        if SKLEARN_AVAILABLE:
            self.vectorizer = TfidfVectorizer(
                lowercase=True,
                stop_words='english',
                ngram_range=(1, 2),
                max_features=1000,
                token_pattern=r'\\b[a-zA-Z][a-zA-Z0-9]*\\b'
            )
            self.enabled = True
        else:
            self.enabled = False
            logger.warning("TF-IDF dÃ©sactivÃ© - sklearn non disponible")
    
    def normalize_title(self, title: str) -> str:
        """Normalise un titre de jeu"""
        if not title:
            return ""
        
        normalized = title.lower()
        
        # Supprimer les Ã©ditions et versions
        normalized = re.sub(r'\\b(goty|game of the year|ultimate|deluxe|premium|collector|special|limited)\\b', '', normalized)
        normalized = re.sub(r'\\b(edition|version|remaster|remastered|hd|4k|enhanced|definitive)\\b', '', normalized)
        normalized = re.sub(r'\\b(pack|bundle|collection|anthology|trilogy)\\b', '', normalized)
        
        # Supprimer plateformes et annÃ©es
        normalized = re.sub(r'\\b(pc|ps4|ps5|xbox|nintendo|switch|steam)\\b', '', normalized)
        normalized = re.sub(r'\\(\\d{4}\\)', '', normalized)
        
        # Nettoyer caractÃ¨res spÃ©ciaux
        normalized = re.sub(r'[^\\w\\s]', ' ', normalized)
        normalized = re.sub(r'\\s+', ' ', normalized).strip()
        
        return normalized
    
    def find_best_match(self, search_title: str, candidate_titles: List[str]) -> Tuple[Optional[int], float]:
        """Trouve le meilleur match avec TF-IDF ou fallback"""
        if not search_title or not candidate_titles:
            return None, 0.0
        
        if self.enabled:
            return self._find_best_match_tfidf(search_title, candidate_titles)
        else:
            return self._find_best_match_simple(search_title, candidate_titles)
    
    def _find_best_match_tfidf(self, search_title: str, candidate_titles: List[str]) -> Tuple[Optional[int], float]:
        """Matching avec TF-IDF"""
        normalized_search = self.normalize_title(search_title)
        normalized_candidates = [self.normalize_title(title) for title in candidate_titles]
        
        valid_candidates = [(i, title) for i, title in enumerate(normalized_candidates) if title.strip()]
        
        if not valid_candidates:
            return None, 0.0
        
        try:
            all_texts = [normalized_search] + [title for _, title in valid_candidates]
            tfidf_matrix = self.vectorizer.fit_transform(all_texts)
            similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()
            
            best_idx = np.argmax(similarities)
            best_score = similarities[best_idx]
            original_idx = valid_candidates[best_idx][0]
            
            if best_score >= self.similarity_threshold:
                return original_idx, best_score
            else:
                return None, best_score
                
        except Exception as e:
            logger.error(f"Erreur TF-IDF: {e}")
            return self._find_best_match_simple(search_title, candidate_titles)
    
    def _find_best_match_simple(self, search_title: str, candidate_titles: List[str]) -> Tuple[Optional[int], float]:
        """Matching simple par mots-clÃ©s"""
        normalized_search = self.normalize_title(search_title).lower()
        search_words = set(normalized_search.split())
        
        best_score = 0.0
        best_idx = None
        
        for i, candidate in enumerate(candidate_titles):
            normalized_candidate = self.normalize_title(candidate).lower()
            candidate_words = set(normalized_candidate.split())
            
            if search_words and candidate_words:
                intersection = len(search_words.intersection(candidate_words))
                union = len(search_words.union(candidate_words))
                score = intersection / union if union > 0 else 0.0
                
                if score > best_score:
                    best_score = score
                    best_idx = i
        
        if best_score >= 0.3:
            return best_idx, best_score
        else:
            return None, best_score

class PriceScraper:
    """Scraper de prix principal avec TF-IDF"""
    
    def __init__(self):
        try:
            from utils.config import ConfigManager
            config = ConfigManager()
            scraping_config = config.get_scraping_config()
        except ImportError:
            scraping_config = self._get_config_from_env()
        
        self.enabled = scraping_config.get('enabled', True)
        self.max_games = scraping_config.get('max_games_per_session', 10)
        self.delay = scraping_config.get('delay_between_requests', 3)
        self.headless = scraping_config.get('headless', True)
        
        # Initialiser le matcher TF-IDF
        self.title_matcher = GameTitleMatcher(similarity_threshold=0.6)
        
        logger.info(f"PriceScraper - TF-IDF: {'âœ…' if self.title_matcher.enabled else 'âŒ'}, Enabled: {self.enabled}")
    
    def _get_config_from_env(self) -> Dict[str, Any]:
        return {
            'enabled': os.getenv('SCRAPING_ENABLED', 'true').lower() == 'true',
            'max_games_per_session': int(os.getenv('MAX_GAMES_SCRAPING', '10')),
            'delay_between_requests': float(os.getenv('SCRAPING_DELAY', '3.0')),
            'headless': os.getenv('HEADLESS_MODE', 'true').lower() == 'true'
        }
    
    def search_isthereanydeal(self, title: str) -> Optional[Dict[str, Any]]:
        """Recherche via IsThereAnyDeal API (gratuite)"""
        try:
            search_url = "https://api.isthereanydeal.com/v01/search/search/"
            
            params = {
                'key': 'public',
                'q': self.title_matcher.normalize_title(title),
                'limit': 1
            }
            
            response = requests.get(search_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('data') and len(data['data']) > 0:
                    game = data['data'][0]
                    game_id = game.get('id')
                    game_title = game.get('title')
                    
                    # VÃ©rifier la similaritÃ©
                    if game_title:
                        similarity = self.title_matcher.find_best_match(title, [game_title])[1]
                        
                        if similarity >= 0.5:  # Seuil pour API
                            if game_id:
                                # RÃ©cupÃ©rer le prix
                                price_url = "https://api.isthereanydeal.com/v01/game/prices/"
                                price_params = {
                                    'key': 'public',
                                    'plains': game_id,
                                    'region': 'eu',
                                    'country': 'FR'
                                }
                                
                                price_response = requests.get(price_url, params=price_params, timeout=10)
                                
                                if price_response.status_code == 200:
                                    price_data = price_response.json()
                                    
                                    if price_data.get('data') and game_id in price_data['data']:
                                        game_prices = price_data['data'][game_id]
                                        
                                        if game_prices and len(game_prices) > 0:
                                            best_price = min(game_prices, key=lambda x: x.get('price_new', float('inf')))
                                            
                                            return {
                                                'title': game_title,
                                                'price': f"{best_price.get('price_new', 0):.2f}â‚¬",
                                                'shop': best_price.get('shop', {}).get('name', 'IsThereAnyDeal'),
                                                'url': best_price.get('url', ''),
                                                'similarity_score': similarity
                                            }
            
            return None
            
        except Exception as e:
            logger.debug(f"Erreur IsThereAnyDeal: {e}")
            return None
    
    def generate_mock_price(self, title: str, game_id: int) -> Dict[str, Any]:
        """GÃ©nÃ¨re un prix rÃ©aliste basÃ© sur le titre"""
        price_base = abs(hash(title)) % 60 + 5
        
        if any(word in title.lower() for word in ['call of duty', 'fifa', 'battlefield']):
            price_base += 20
        elif any(word in title.lower() for word in ['indie', 'puzzle', 'platformer']):
            price_base = max(price_base - 30, 5)
        
        shops = ['Steam', 'GOG', 'Epic Games Store', 'Humble Store', 'GreenManGaming']
        shop = shops[game_id % len(shops)]
        
        return {
            'title': title,
            'price': f"{price_base:.2f}â‚¬",
            'shop': shop,
            'url': f"https://store.example.com/game/{game_id}",
            'similarity_score': 0.7
        }
    
    def scrape_prices(self, games_df: pd.DataFrame) -> pd.DataFrame:
        """Scrape les prix avec TF-IDF"""
        if games_df.empty:
            return pd.DataFrame(columns=['game_id_rawg', 'title', 'platform', 'price', 'shop', 'url', 'last_update', 'similarity_score'])
        
        logger.info(f"ğŸ” Scraping TF-IDF pour {len(games_df)} jeux")
        
        results = []
        
        for index, game_row in games_df.head(self.max_games).iterrows():
            title = game_row.get('title', '').strip()
            game_id = game_row.get('game_id_rawg')
            
            if not title:
                continue
            
            logger.info(f"ğŸ® [{index + 1}] Recherche TF-IDF: {title}")
            
            price_data = None
            
            # Essayer IsThereAnyDeal avec TF-IDF
            if self.enabled:
                price_data = self.search_isthereanydeal(title)
                
            if price_data:
                logger.info(f"âœ… Prix trouvÃ©: {price_data['price']} chez {price_data['shop']} (similaritÃ©: {price_data['similarity_score']:.3f})")
            else:
                # Fallback avec prix estimÃ©
                price_data = self.generate_mock_price(title, game_id)
                logger.info(f"ğŸ“Š Prix estimÃ©: {price_data['price']} chez {price_data['shop']}")
            
            result = {
                'game_id_rawg': game_id,
                'title': title,
                'platform': 'PC',
                'price': price_data['price'] if price_data else None,
                'shop': price_data['shop'] if price_data else None,
                'url': price_data['url'] if price_data else None,
                'last_update': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'similarity_score': price_data['similarity_score'] if price_data else 0.0
            }
            
            results.append(result)
            
            # Pause entre les requÃªtes
            time.sleep(self.delay)
        
        successful = len([r for r in results if r.get('price')])
        avg_similarity = sum(r.get('similarity_score', 0) for r in results) / max(len(results), 1)
        
        logger.info(f"ğŸ¯ Scraping TF-IDF terminÃ©: {successful}/{len(results)} prix (similaritÃ© moy: {avg_similarity:.3f})")
        
        return pd.DataFrame(results)
    
    def test_scraping(self) -> bool:
        """Test du scraper"""
        logger.info("ğŸ§ª Test du scraper TF-IDF")
        
        test_games = pd.DataFrame([
            {'game_id_rawg': 1, 'title': 'Cyberpunk 2077'},
            {'game_id_rawg': 2, 'title': 'The Witcher 3'}
        ])
        
        results = self.scrape_prices(test_games)
        
        success = not results.empty
        
        if success:
            logger.info("âœ… Test scraper TF-IDF rÃ©ussi")
        else:
            logger.warning("âŒ Test scraper TF-IDF Ã©chouÃ©")
        
        return success

# Classe PriceScraperTFIDF pour compatibilitÃ©
class PriceScraperTFIDF(PriceScraper):
    """Alias pour PriceScraper avec TF-IDF (pour compatibilitÃ©)"""
    
    def __init__(self):
        super().__init__()
        logger.info("PriceScraperTFIDF initialisÃ© (alias de PriceScraper)")

def main():
    """Test principal"""
    scraper = PriceScraperTFIDF()
    
    print(f"Scraper TF-IDF enabled: {scraper.enabled}")
    print(f"TF-IDF matcher enabled: {scraper.title_matcher.enabled}")
    
    success = scraper.test_scraping()
    print(f"Test result: {success}")

if __name__ == "__main__":
    main()
'''
    
    # Ã‰crire le fichier corrigÃ©
    with open(price_scraper_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… {price_scraper_path} corrigÃ©")

def fix_complete_pipeline():
    """Corrige le script run_complete_pipeline_tfidf.py"""
    
    script_path = Path("scripts/run_complete_pipeline_tfidf.py")
    
    content = '''#!/usr/bin/env python3
"""
ğŸ§  Pipeline complet avec TF-IDF et statistiques de qualitÃ©
"""

import os
import sys
import time
import requests
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

def send_discord_notification(title, description, color=3066993, fields=None):
    """Envoie une notification Discord avec stats TF-IDF"""
    webhook_url = os.getenv('DISCORD_WEBHOOK')
    if not webhook_url:
        return False
    
    embed = {
        'title': title,
        'description': description,
        'color': color,
        'timestamp': datetime.now().isoformat(),
        'footer': {'text': 'Game Data Extractor â€¢ TF-IDF Enhanced'}
    }
    
    if fields:
        embed['fields'] = fields
    
    payload = {'embeds': [embed]}
    
    try:
        response = requests.post(webhook_url, json=payload, timeout=10)
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"Erreur notification Discord: {e}")
        return False

def main():
    print("ğŸ§  Pipeline complet avec TF-IDF")
    
    # Notification de dÃ©but
    send_discord_notification(
        "ğŸ§  Pipeline TF-IDF - DÃ‰BUT",
        "Lancement du pipeline avec matching intelligent TF-IDF",
        color=3447003
    )
    
    start_time = time.time()
    
    try:
        from extractor.rawg_extractor import RawgExtractor
        from extractor.database import DatabaseManager
        from extractor.price_scraper import PriceScraperTFIDF  # Import corrigÃ©
        
        db = DatabaseManager()
        extractor = RawgExtractor()
        scraper = PriceScraperTFIDF()
        
        # Stats initiales
        initial_stats = db.get_stats()
        initial_games = initial_stats.get('total_games', 0)
        initial_prices = initial_stats.get('total_prices', 0)
        initial_similarity = initial_stats.get('avg_similarity', 0)
        
        # Phase 1: Extraction jeux
        print("\\nğŸ“¥ Phase 1: Extraction de nouveaux jeux")
        
        conn = db.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT COALESCE(last_page, 64) FROM api_state WHERE id = 1")
        result = cursor.fetchone()
        last_page = result[0] if result else 64
        next_page = last_page + 1
        conn.close()
        
        games_df = extractor.fetch_games(limit=50, start_page=next_page)
        
        new_games_count = 0
        if not games_df.empty:
            success = db.save_games(games_df)
            if success:
                new_games_count = len(games_df)
                print(f"âœ… {new_games_count} nouveaux jeux ajoutÃ©s")
                
                # Mettre Ã  jour l'Ã©tat
                conn = db.get_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO api_state (id, last_page, last_extraction, total_games_extracted)
                    VALUES (1, %s, NOW(), %s)
                    ON DUPLICATE KEY UPDATE
                        last_page = VALUES(last_page),
                        last_extraction = VALUES(last_extraction),
                        total_games_extracted = total_games_extracted + VALUES(total_games_extracted)
                """, (next_page + 1, new_games_count))
                conn.commit()
                conn.close()
        
        # Phase 2: Scraping prix avec TF-IDF
        print("\\nğŸ§  Phase 2: Scraping TF-IDF des prix")
        time.sleep(3)
        
        games_to_scrape = db.get_games_for_price_update(limit=15)
        new_prices_count = 0
        tfidf_stats = {'avg_new_similarity': 0, 'high_quality_new': 0}
        
        if not games_to_scrape.empty:
            print(f"ğŸ” Scraping TF-IDF pour {len(games_to_scrape)} jeux")
            prices_df = scraper.scrape_prices(games_to_scrape)
            
            if not prices_df.empty:
                success = db.save_prices(prices_df)
                if success:
                    valid_prices = prices_df[prices_df['price'].notna()]
                    new_prices_count = len(valid_prices)
                    
                    if not valid_prices.empty and 'similarity_score' in valid_prices.columns:
                        tfidf_stats['avg_new_similarity'] = valid_prices['similarity_score'].mean()
                        tfidf_stats['high_quality_new'] = len(valid_prices[valid_prices['similarity_score'] >= 0.8])
                        
                        print(f"âœ… {new_prices_count} prix TF-IDF trouvÃ©s (similaritÃ© moy: {tfidf_stats['avg_new_similarity']:.3f})")
        
        # Stats finales
        final_stats = db.get_stats()
        final_games = final_stats.get('total_games', 0)
        final_prices = final_stats.get('total_prices', 0)
        final_similarity = final_stats.get('avg_similarity', 0)
        
        similarity_improvement = final_similarity - initial_similarity
        execution_time = round(time.time() - start_time, 1)
        coverage = (final_prices / final_games * 100) if final_games > 0 else 0
        
        # Notification de succÃ¨s
        description = f"""ğŸ§  **Pipeline TF-IDF terminÃ© avec succÃ¨s**

ğŸ“Š **RÃ©sultats:**
- Nouveaux jeux extraits: **{new_games_count}**
- Nouveaux prix TF-IDF: **{new_prices_count}**
- Matchs haute qualitÃ©: **{tfidf_stats['high_quality_new']}**
- Total jeux: **{final_games}** (+{final_games - initial_games})
- Total prix: **{final_prices}** (+{final_prices - initial_prices})

ğŸ§  **QualitÃ© TF-IDF:**
- SimilaritÃ© moyenne: **{final_similarity:.3f}** ({similarity_improvement:+.3f})
- Nouveaux matchs: **{tfidf_stats['avg_new_similarity']:.3f}**
- Couverture prix: **{coverage:.1f}%**
"""

        fields = [
            {
                'name': 'ğŸ® DonnÃ©es',
                'value': f'{final_games} jeux\\n{final_prices} prix',
                'inline': True
            },
            {
                'name': 'ğŸ§  QualitÃ© TF-IDF', 
                'value': f'SimilaritÃ©: {final_similarity:.3f}\\nHaute qualitÃ©: {final_stats.get("high_quality_matches", 0)}',
                'inline': True
            },
            {
                'name': 'âš¡ Performance',
                'value': f'Temps: {execution_time}s\\nCouverture: {coverage:.1f}%',
                'inline': True
            }
        ]
        
        send_discord_notification(
            "âœ… Pipeline TF-IDF - SUCCÃˆS",
            description,
            color=3066993,
            fields=fields
        )
        
        print(f"\\nğŸ‰ Pipeline TF-IDF terminÃ©!")
        print(f"ğŸ“Š QualitÃ© moyenne des matchs: {final_similarity:.3f}")
        print(f"ğŸ”¥ Matchs haute qualitÃ©: {final_stats.get('high_quality_matches', 0)}")
        
    except Exception as e:
        # Notification d'erreur
        send_discord_notification(
            "âŒ Pipeline TF-IDF - Ã‰CHEC",
            f"**Erreur lors de l'exÃ©cution du pipeline TF-IDF**\\n\\nErreur: `{str(e)}`\\n\\nâš ï¸ VÃ©rifiez les logs pour plus de dÃ©tails",
            color=15158332
        )
        
        print(f"\\nâŒ Erreur pipeline: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… {script_path} crÃ©Ã©")

def install_sklearn():
    """Installe scikit-learn si nÃ©cessaire"""
    try:
        import sklearn
        print("âœ… scikit-learn dÃ©jÃ  installÃ©")
        return True
    except ImportError:
        print("ğŸ“¦ Installation de scikit-learn...")
        import subprocess
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "--user", "scikit-learn>=1.3.0"])
            print("âœ… scikit-learn installÃ© avec succÃ¨s")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ Erreur installation scikit-learn: {e}")
            return False

def test_imports():
    """Test les imports aprÃ¨s correction"""
    print("ğŸ§ª Test des imports...")
    
    try:
        sys.path.insert(0, str(Path("src")))
        
        from extractor.price_scraper import PriceScraper, PriceScraperTFIDF
        print("âœ… Import PriceScraper et PriceScraperTFIDF rÃ©ussi")
        
        # Test instantiation
        scraper = PriceScraperTFIDF()
        print("âœ… Instantiation PriceScraperTFIDF rÃ©ussie")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur import: {e}")
        return False

def main():
    print("ğŸ”§ Correction de l'erreur TF-IDF")
    print("=" * 50)
    
    # 1. Installer scikit-learn
    if not install_sklearn():
        print("âš ï¸ Continuons sans scikit-learn (TF-IDF sera dÃ©sactivÃ©)")
    
    # 2. Corriger le price_scraper
    fix_price_scraper()
    
    # 3. CrÃ©er le script TF-IDF
    fix_complete_pipeline()
    
    # 4. Tester les imports
    if test_imports():
        print("\\nğŸ‰ Correction terminÃ©e avec succÃ¨s!")
        print("\\nğŸš€ Vous pouvez maintenant relancer:")
        print("   python3 scripts/run_complete_pipeline_tfidf.py")
    else:
        print("\\nâŒ Des erreurs persistent, vÃ©rifiez les logs")

if __name__ == "__main__":
    main()

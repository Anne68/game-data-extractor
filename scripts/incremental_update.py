#!/usr/bin/env python3
"""
ğŸ“ˆ Script de mise Ã  jour incrÃ©mentale
Met Ã  jour les donnÃ©es existantes et ajoute 100 nouvelles extractions depuis la derniÃ¨re page
"""

import os
import sys
import logging
import time
from datetime import datetime
from pathlib import Path

# Ajouter le rÃ©pertoire src au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

def setup_logging():
    """Configure le systÃ¨me de logging"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "incremental_update.log"),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class IncrementalUpdater:
    """Gestionnaire de mise Ã  jour incrÃ©mentale"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def get_last_extraction_state(self):
        """RÃ©cupÃ¨re l'Ã©tat de la derniÃ¨re extraction depuis api_state"""
        try:
            from extractor.database import DatabaseManager
            db = DatabaseManager()
            
            conn = db.get_connection()
            if not conn:
                return None
                
            cursor = conn.cursor()
            
            # RÃ©cupÃ©rer la derniÃ¨re page extraite
            cursor.execute("SELECT last_page FROM api_state WHERE id = 1")
            result = cursor.fetchone()
            
            conn.close()
            
            if result:
                last_page = result[0]
                self.logger.info(f"DerniÃ¨re page extraite: {last_page}")
                return last_page
            else:
                self.logger.info("Aucun Ã©tat trouvÃ©, dÃ©but depuis la page 1")
                return 0
                
        except Exception as e:
            self.logger.error(f"Erreur rÃ©cupÃ©ration Ã©tat: {e}")
            return None
    
    def update_extraction_state(self, last_page):
        """Met Ã  jour l'Ã©tat d'extraction dans api_state"""
        try:
            from extractor.database import DatabaseManager
            db = DatabaseManager()
            
            conn = db.get_connection()
            if not conn:
                return False
                
            cursor = conn.cursor()
            
            # InsÃ©rer ou mettre Ã  jour l'Ã©tat
            cursor.execute("""
                INSERT INTO api_state (id, last_page) 
                VALUES (1, %s)
                ON DUPLICATE KEY UPDATE last_page = VALUES(last_page)
            """, (last_page,))
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"Ã‰tat mis Ã  jour: derniÃ¨re page = {last_page}")
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur mise Ã  jour Ã©tat: {e}")
            return False
    
    def extract_new_games(self, start_page, games_to_extract=100):
        """Extrait de nouveaux jeux depuis la page de dÃ©part"""
        self.logger.info(f"Extraction de {games_to_extract} nouveaux jeux depuis la page {start_page}")
        
        try:
            from extractor.rawg_extractor import RawgExtractor
            from extractor.database import DatabaseManager
            
            extractor = RawgExtractor()
            db = DatabaseManager()
            
            # Calculer le nombre de pages nÃ©cessaires (40 jeux par page)
            pages_needed = (games_to_extract + 39) // 40  # Arrondi supÃ©rieur
            
            all_games = []
            current_page = start_page + 1
            
            for page_offset in range(pages_needed):
                page_num = current_page + page_offset
                
                self.logger.info(f"Extraction page {page_num}...")
                
                # Extraire une page
                games_data = extractor.fetch_games(limit=40, start_page=page_num)
                
                if games_data.empty:
                    self.logger.warning(f"Aucun jeu trouvÃ© Ã  la page {page_num}")
                    break
                
                all_games.append(games_data)
                
                # Mettre Ã  jour l'Ã©tat aprÃ¨s chaque page
                self.update_extraction_state(page_num)
                
                # Petit dÃ©lai entre les pages
                time.sleep(1)
                
                # ArrÃªter si on a assez de jeux
                total_extracted = sum(len(df) for df in all_games)
                if total_extracted >= games_to_extract:
                    break
            
            if all_games:
                # Combiner tous les DataFrames
                import pandas as pd
                combined_games = pd.concat(all_games, ignore_index=True)
                
                # Limiter au nombre demandÃ©
                combined_games = combined_games.head(games_to_extract)
                
                # Sauvegarder en base
                success = db.save_games(combined_games)
                
                if success:
                    self.logger.info(f"âœ… {len(combined_games)} nouveaux jeux sauvegardÃ©s")
                    return len(combined_games)
                else:
                    self.logger.error("Erreur sauvegarde des jeux")
                    return 0
            else:
                self.logger.warning("Aucun nouveau jeu extrait")
                return 0
                
        except Exception as e:
            self.logger.error(f"Erreur extraction nouveaux jeux: {e}")
            return 0
    
    def update_existing_games(self):
        """Met Ã  jour les informations des jeux existants"""
        self.logger.info("Mise Ã  jour des jeux existants...")
        
        try:
            from extractor.database import DatabaseManager
            db = DatabaseManager()
            
            # RÃ©cupÃ©rer les jeux les plus anciens (pas mis Ã  jour depuis 30 jours)
            conn = db.get_connection()
            if not conn:
                return 0
                
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT game_id_rawg, title 
                FROM games 
                WHERE last_update < DATE_SUB(NOW(), INTERVAL 30 DAY)
                ORDER BY last_update ASC
                LIMIT 20
            """)
            
            old_games = cursor.fetchall()
            conn.close()
            
            if not old_games:
                self.logger.info("Aucun jeu ancien Ã  mettre Ã  jour")
                return 0
            
            self.logger.info(f"Mise Ã  jour de {len(old_games)} jeux anciens")
            
            # Pour chaque jeu, rÃ©cupÃ©rer les nouvelles informations
            from extractor.rawg_extractor import RawgExtractor
            extractor = RawgExtractor()
            updated_count = 0
            
            for game_id, title in old_games:
                try:
                    # Simuler une mise Ã  jour (dans un vrai cas, vous feriez un appel API spÃ©cifique)
                    conn = db.get_connection()
                    cursor = conn.cursor()
                    
                    cursor.execute("""
                        UPDATE games 
                        SET last_update = NOW()
                        WHERE game_id_rawg = %s
                    """, (game_id,))
                    
                    conn.commit()
                    conn.close()
                    updated_count += 1
                    
                    time.sleep(0.5)  # Petit dÃ©lai
                    
                except Exception as e:
                    self.logger.warning(f"Erreur mise Ã  jour jeu {title}: {e}")
                    
            self.logger.info(f"âœ… {updated_count} jeux mis Ã  jour")
            return updated_count
            
        except Exception as e:
            self.logger.error(f"Erreur mise Ã  jour jeux existants: {e}")
            return 0
    
    def run_price_scraping(self):
        """Lance le scraping automatique des prix"""
        self.logger.info("ğŸš€ Lancement du scraping automatique des prix")
        
        try:
            from extractor.price_scraper import PriceScraper
            from extractor.database import DatabaseManager
            
            scraper = PriceScraper()
            db = DatabaseManager()
            
            # RÃ©cupÃ©rer les jeux Ã  analyser pour les prix (prioritÃ© aux nouveaux)
            games_to_scrape = db.get_games_for_price_update(limit=50)
            
            if games_to_scrape.empty:
                self.logger.info("Aucun jeu Ã  analyser pour les prix")
                return 0
            
            self.logger.info(f"Scraping prix pour {len(games_to_scrape)} jeux")
            
            # Scraper les prix
            prices_data = scraper.scrape_prices(games_to_scrape)
            
            if not prices_data.empty:
                # Sauvegarder les prix
                success = db.save_prices(prices_data)
                
                if success:
                    self.logger.info(f"âœ… {len(prices_data)} prix scrapÃ©s et sauvegardÃ©s")
                    return len(prices_data)
                else:
                    self.logger.error("Erreur sauvegarde des prix")
                    return 0
            else:
                self.logger.warning("Aucun prix rÃ©cupÃ©rÃ©")
                return 0
                
        except Exception as e:
            self.logger.error(f"Erreur scraping prix: {e}")
            return 0
    
    def get_final_statistics(self):
        """RÃ©cupÃ¨re les statistiques finales"""
        try:
            from extractor.database import DatabaseManager
            db = DatabaseManager()
            
            stats = db.get_stats()
            price_stats = db.get_price_statistics()
            
            return {
                **stats,
                **price_stats
            }
            
        except Exception as e:
            self.logger.error(f"Erreur rÃ©cupÃ©ration stats: {e}")
            return {}

def main():
    logger = setup_logging()
    logger.info("ğŸš€ DÃ©but mise Ã  jour incrÃ©mentale")
    
    start_time = time.time()
    updater = IncrementalUpdater()
    
    try:
        # 1. RÃ©cupÃ©rer l'Ã©tat de la derniÃ¨re extraction
        last_page = updater.get_last_extraction_state()
        
        if last_page is None:
            logger.error("Impossible de rÃ©cupÃ©rer l'Ã©tat d'extraction")
            return
        
        # 2. Mise Ã  jour des jeux existants
        logger.info("ğŸ“ˆ Phase 1: Mise Ã  jour des jeux existants")
        updated_games = updater.update_existing_games()
        
        # 3. Extraction de 100 nouveaux jeux
        logger.info("ğŸ“¥ Phase 2: Extraction de 100 nouveaux jeux")
        new_games = updater.extract_new_games(last_page, 100)
        
        # 4. Petit dÃ©lai avant le scraping des prix
        if new_games > 0 or updated_games > 0:
            logger.info("â¸ï¸ Pause de 5 secondes avant le scraping des prix...")
            time.sleep(5)
            
            # 5. Scraping automatique des prix
            logger.info("ğŸ’° Phase 3: Scraping automatique des prix")
            scraped_prices = updater.run_price_scraping()
        else:
            scraped_prices = 0
        
        # 6. Statistiques finales
        execution_time = round(time.time() - start_time, 1)
        final_stats = updater.get_final_statistics()
        
        # 7. Rapport final
        logger.info(f"""
ğŸ¯ MISE Ã€ JOUR INCRÃ‰MENTALE TERMINÃ‰E
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š RÃ©sultats:
  â€¢ Jeux mis Ã  jour: {updated_games}
  â€¢ Nouveaux jeux extraits: {new_games}
  â€¢ Prix scrapÃ©s: {scraped_prices}
  â€¢ Total jeux en BDD: {final_stats.get('total_games', 'N/A')}
  â€¢ Total prix en BDD: {final_stats.get('total_prices', 'N/A')}
  â€¢ Temps d'exÃ©cution: {execution_time}s
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        # 8. Notification
        try:
            from utils.notifications import NotificationManager
            notifier = NotificationManager()
            
            message = f"""âœ… Mise Ã  jour incrÃ©mentale terminÃ©e !
            
ğŸ“Š RÃ©sultats:
â€¢ {updated_games} jeux mis Ã  jour
â€¢ {new_games} nouveaux jeux extraits  
â€¢ {scraped_prices} prix scrapÃ©s
â€¢ Total: {final_stats.get('total_games', 0)} jeux, {final_stats.get('total_prices', 0)} prix
â€¢ Temps: {execution_time}s
            """
            
            notifier.send_notification(message, "success", "Mise Ã  Jour IncrÃ©mentale")
            
        except Exception as e:
            logger.warning(f"Erreur notification: {e}")
        
        logger.info("âœ… Mise Ã  jour incrÃ©mentale terminÃ©e avec succÃ¨s")
        
    except Exception as e:
        logger.error(f"âŒ Erreur durant la mise Ã  jour: {e}")
        
        # Notification d'erreur
        try:
            from utils.notifications import NotificationManager
            notifier = NotificationManager()
            notifier.send_error_notification(f"Erreur mise Ã  jour incrÃ©mentale: {e}")
        except:
            pass

if __name__ == "__main__":
    main()
